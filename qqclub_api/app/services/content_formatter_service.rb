# å†…å®¹æ ¼å¼åŒ–æœåŠ¡
# è´Ÿè´£å¤„ç†æ‰“å¡å†…å®¹çš„æ ¼å¼åŒ–ã€åˆ†æ®µã€è¡¨æƒ…è½¬æ¢ç­‰
class ContentFormatterService
  include ActionView::Helpers::TextHelper
  include ActionView::Helpers::SanitizeHelper

  # è¡¨æƒ…ç¬¦å·æ˜ å°„
  EMOJI_MAPPING = {
    'å¼€å¿ƒ' => 'ğŸ˜Š',
    'å¿«ä¹' => 'ğŸ˜„',
    'å“ˆå“ˆ' => 'ğŸ˜‚',
    'å–œæ¬¢' => 'â¤ï¸',
    'çˆ±' => 'ğŸ’•',
    'èµ' => 'ğŸ‘',
    'åŠ æ²¹' => 'ğŸ’ª',
    'æ€è€ƒ' => 'ğŸ¤”',
    'å­¦ä¹ ' => 'ğŸ“š',
    'é˜…è¯»' => 'ğŸ“–',
    'è¿›æ­¥' => 'ğŸ“ˆ',
    'åŠªåŠ›' => 'ğŸŒŸ',
    'æ„Ÿè°¢' => 'ğŸ™',
    'æ£’' => 'ğŸ‘',
    'å¥½' => 'ğŸ‘Œ',
    'æ”¯æŒ' => 'ğŸ’¯',
    'é¼“åŠ±' => 'ğŸ‰',
    'æ”¶è·' => 'ğŸŒ±',
    'æˆé•¿' => 'ğŸŒ¿'
  }.freeze

  # æ•æ„Ÿè¯åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
  SENSITIVE_WORDS = %w[
    è¿æ³• æš´åŠ› è‰²æƒ… èµŒåš æ¯’å“
    # å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨æ›´å®Œæ•´çš„æ•æ„Ÿè¯åº“
  ].freeze

  class << self
    # æ ¼å¼åŒ–å†…å®¹ä¸»ä½“æ–¹æ³•
    def format(content, options = {})
      formatted_content = content.dup

      # åº”ç”¨å„ç§æ ¼å¼åŒ–å¤„ç†
      formatted_content = sanitize_content(formatted_content)
      formatted_content = convert_emojis(formatted_content)
      formatted_content = format_paragraphs(formatted_content)
      formatted_content = highlight_keywords(formatted_content, options[:keywords]) if options[:keywords].present?
      formatted_content = add_hashtag_links(formatted_content) if options[:enable_hashtags]
      formatted_content = truncate_content(formatted_content, options[:length]) if options[:length].present?

      formatted_content
    end

    # ç”Ÿæˆå†…å®¹æ‘˜è¦
    def generate_summary(content, max_length = 200)
      # æ¸…ç†å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦
      cleaned = sanitize_content(content)
      cleaned = remove_formatting(cleaned)

      if cleaned.length > max_length
        # å°è¯•åœ¨å¥å·æˆ–æ¢è¡Œç¬¦å¤„æˆªæ–­
        truncated = cleaned.truncate(max_length, separator: /[,ï¼Œ.ã€‚!ï¼?ï¼Ÿ\n]/)
        truncated += "..." unless truncated.end_with?('.')
        truncated
      else
        cleaned
      end
    end

    # æå–å…³é”®è¯
    def extract_keywords(content, max_keywords = 5)
      cleaned = sanitize_content(content)

      # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPç®—æ³•ï¼‰
      words = cleaned.scan(/[\u4e00-\u9fa5]+|[a-zA-Z]+/)
                      .reject { |word| word.length < 2 }
                      .group_by(&:itself)
                      .transform_values(&:count)
                      .sort_by { |_, count| -count }
                      .first(max_keywords)
                      .map(&:first)

      words
    end

    # è®¡ç®—å†…å®¹è´¨é‡åˆ†æ•°
    def calculate_quality_score(content)
      score = 0

      # åŸºç¡€åˆ†æ•°ï¼ˆé•¿åº¦è¦æ±‚ï¼‰
      length = content.length
      if length >= 50
        score += 10
      elsif length >= 100
        score += 20
      elsif length >= 200
        score += 30
      end

      # æ®µè½ç»“æ„åˆ†æ•°
      paragraphs = content.split(/\n\n+/).length
      score += [paragraphs * 2, 10].min

      # å…³é”®è¯å¤šæ ·æ€§åˆ†æ•°
      keywords = extract_keywords(content, 10).length
      score += keywords * 2

      # è¡¨æƒ…ç¬¦å·ä½¿ç”¨åˆ†æ•°
      emoji_count = content.scan(/[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]/).length
      score += [emoji_count, 5].min

      # æ•æ„Ÿè¯æ£€æµ‹æ‰£åˆ†
      sensitive_count = count_sensitive_words(content)
      score -= sensitive_count * 10

      [score, 0].max # ç¡®ä¿åˆ†æ•°ä¸ä¸ºè´Ÿ
    end

    # æ£€æŸ¥å†…å®¹åˆè§„æ€§
    def check_compliance(content)
      issues = []

      # æ£€æŸ¥æ•æ„Ÿè¯
      sensitive_words = find_sensitive_words(content)
      if sensitive_words.any?
        issues << {
          type: 'sensitive_words',
          message: "å†…å®¹åŒ…å«æ•æ„Ÿè¯ï¼š#{sensitive_words.join(', ')}",
          severity: 'high'
        }
      end

      # æ£€æŸ¥é•¿åº¦
      if content.length < 50
        issues << {
          type: 'too_short',
          message: "å†…å®¹å¤ªçŸ­ï¼Œè‡³å°‘éœ€è¦50ä¸ªå­—",
          severity: 'medium'
        }
      end

      # æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤å†…å®¹
      if is_duplicate_content?(content)
        issues << {
          type: 'duplicate',
          message: "å†…å®¹ç–‘ä¼¼é‡å¤",
          severity: 'low'
        }
      end

      # æ£€æŸ¥æ ¼å¼
      if content.match?(/^[^\n]*$/) # æ²¡æœ‰æ¢è¡Œ
        issues << {
          type: 'poor_formatting',
          message: "å»ºè®®åˆ†æ®µä»¥æé«˜å¯è¯»æ€§",
          severity: 'low'
        }
      end

      {
        compliant: issues.empty?,
        issues: issues,
        score: calculate_quality_score(content)
      }
    end

    private

    # æ¸…ç†å†…å®¹ï¼Œç§»é™¤ä¸å®‰å…¨çš„HTML
    def sanitize_content(content)
      # ç®€å•çš„HTMLæ¸…ç†å®ç°
      cleaned = content.dup
      cleaned.gsub!(/<script[^>]*>.*?<\/script>/mi, '')
      cleaned.gsub!(/<style[^>]*>.*?<\/style>/mi, '')
      cleaned.gsub!(/<[^>]*>/, '')
      cleaned.strip
    end

    # è½¬æ¢è¡¨æƒ…ç¬¦å·
    def convert_emojis(content)
      formatted = content.dup

      EMOJI_MAPPING.each do |text, emoji|
        formatted.gsub!(/#{text}/i, emoji)
      end

      formatted
    end

    # æ ¼å¼åŒ–æ®µè½
    def format_paragraphs(content)
      # å°†è¿ç»­çš„æ¢è¡Œç¬¦è½¬æ¢ä¸ºæ®µè½
      paragraphs = content.split(/\n\n+/)

      formatted_paragraphs = paragraphs.map do |paragraph|
        # å¤„ç†å•ä¸ªæ®µè½å†…çš„æ¢è¡Œ
        lines = paragraph.split(/\n/)

        if lines.length == 1
          # å•è¡Œå†…å®¹
          "<p>#{lines.first.strip}</p>"
        else
          # å¤šè¡Œå†…å®¹ï¼Œä½¿ç”¨<br>è¿æ¥
          "<p>#{lines.map(&:strip).join('<br>')}</p>"
        end
      end

      formatted_paragraphs.join("\n")
    end

    # é«˜äº®å…³é”®è¯
    def highlight_keywords(content, keywords)
      formatted = content.dup

      Array(keywords).each do |keyword|
        next if keyword.blank?
        formatted.gsub!(/(#{Regexp.escape(keyword)})/i, '<mark>\1</mark>')
      end

      formatted
    end

    # æ·»åŠ è¯é¢˜æ ‡ç­¾é“¾æ¥
    def add_hashtag_links(content)
      content.gsub(/#([^#\s]+)#?/) do |match|
        hashtag = $1
        "<a href='/search?q=%23#{hashtag}' class='hashtag'>##{hashtag}</a>"
      end
    end

    # æˆªæ–­å†…å®¹
    def truncate_content(content, length)
      # ç®€å•çš„æˆªæ–­å®ç°
      if content.length > length
        last_space = content.rindex(' ', length - 3)
        if last_space && last_space > 0
          content[0, last_space] + "..."
        else
          content[0, length - 3] + "..."
        end
      else
        content
      end
    end

    # ç§»é™¤æ ¼å¼åŒ–æ ‡ç­¾
    def remove_formatting(content)
      # ç§»é™¤æ‰€æœ‰HTMLæ ‡ç­¾
      content.gsub(/<[^>]*>/, '').strip
    end

    # ç»Ÿè®¡æ•æ„Ÿè¯æ•°é‡
    def count_sensitive_words(content)
      count = 0
      SENSITIVE_WORDS.each do |word|
        count += content.scan(/#{word}/i).length
      end
      count
    end

    # æŸ¥æ‰¾æ•æ„Ÿè¯
    def find_sensitive_words(content)
      found_words = []

      SENSITIVE_WORDS.each do |word|
        if content.match?(/#{word}/i)
          found_words << word
        end
      end

      found_words
    end

    # æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤å†…å®¹ï¼ˆç®€åŒ–ç‰ˆï¼‰
    def is_duplicate_content?(content)
      # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„é‡å¤å†…å®¹æ£€æµ‹ç®—æ³•
      # æ¯”å¦‚è®¡ç®—æ–‡æœ¬æŒ‡çº¹ã€ä¸å†å²è®°å½•å¯¹æ¯”ç­‰

      # ç®€å•çš„é‡å¤æ£€æµ‹ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å¤§é‡é‡å¤å­—ç¬¦
      max_consecutive_chars = content.scan(/(.)\1{5,}/).length
      return true if max_consecutive_chars > 0

      # æ£€æŸ¥æ˜¯å¦å¤§éƒ¨åˆ†å†…å®¹éƒ½æ˜¯æ ‡ç‚¹ç¬¦å·
      punctuation_ratio = content.count('.,!?;:ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š').to_f / content.length
      return true if punctuation_ratio > 0.3

      false
    end

    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸¾æŠ¥
    def should_report_content?(content, check_in = nil)
      compliance = check_compliance(content)

      # åŒ…å«æ•æ„Ÿè¯çš„å»ºè®®è‡ªåŠ¨ä¸¾æŠ¥
      if compliance[:issues].any? { |issue| issue[:type] == 'sensitive_words' }
        return {
          should_report: true,
          reason: :sensitive_words,
          auto_report: true,
          detected_words: compliance[:issues].find { |i| i[:type] == 'sensitive_words' }&.dig(:detected_words) || []
        }
      end

      # è´¨é‡åˆ†æ•°è¿‡ä½çš„å»ºè®®ä¸¾æŠ¥
      if compliance[:score] < 20
        return {
          should_report: true,
          reason: :inappropriate_content,
          auto_report: false,
          quality_score: compliance[:score]
        }
      end

      { should_report: false }
    end

    # ç”Ÿæˆä¸¾æŠ¥å»ºè®®
    def generate_report_suggestion(content, check_in = nil)
      analysis = should_report_content?(content, check_in)

      if analysis[:should_report]
        suggestion = case analysis[:reason]
                    when :sensitive_words
                      {
                        reason: :sensitive_words,
                        message: "å†…å®¹åŒ…å«æ•æ„Ÿè¯ï¼š#{analysis[:detected_words].join(', ')}",
                        auto_report: analysis[:auto_report],
                        priority: 'high'
                      }
                    when :inappropriate_content
                      {
                        reason: :inappropriate_content,
                        message: "å†…å®¹è´¨é‡è¿‡ä½ï¼Œå¯èƒ½åŒ…å«ä¸å½“å†…å®¹",
                        auto_report: false,
                        priority: 'medium'
                      }
                    else
                      {
                        reason: :other,
                        message: "å†…å®¹å¯èƒ½éœ€è¦äººå·¥å®¡æ ¸",
                        auto_report: false,
                        priority: 'low'
                      }
                    end
      else
        suggestion = {
          reason: nil,
          message: "å†…å®¹æ­£å¸¸ï¼Œæ— éœ€ä¸¾æŠ¥",
          auto_report: false,
          priority: 'low'
        }
      end

      suggestion.merge(
        compliance: check_compliance(content),
        sensitive_words: find_sensitive_words(content),
        quality_score: calculate_quality_score(content)
      )
    end

    # æ£€æŸ¥ç”¨æˆ·ä¸¾æŠ¥æƒé™
    def can_report_content?(user, check_in)
      # ä¸èƒ½ä¸¾æŠ¥è‡ªå·±çš„å†…å®¹
      return false if user == check_in.user

      # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸¾æŠ¥è¿‡
      existing_report = ContentReport.find_by(user: user, check_in: check_in)
      return false if existing_report

      true
    end

    # é¢„å¤„ç†ä¸¾æŠ¥å†…å®¹
    def preprocess_report_content(content)
      # æ¸…ç†å’Œé¢„å¤„ç†ä¸¾æŠ¥å†…å®¹
      sanitized = sanitize_content(content)
      # ç®€å•çš„æˆªæ–­å®ç°
      if sanitized.length > 1000
        truncated = sanitized[0, 997] + "..."
      else
        truncated = sanitized
      end
      truncated.strip
    end
  end
end